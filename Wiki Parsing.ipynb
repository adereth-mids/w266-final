{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import xml.etree.cElementTree as ET\n",
    "from IPython.display import clear_output\n",
    "from ipywidgets import FloatProgress, IntText\n",
    "from IPython.display import display\n",
    "from nltk.tokenize.stanford import StanfordTokenizer\n",
    "from nltk.tokenize import word_tokenize\n",
    "import nltk\n",
    "import time\n",
    "import re\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NLTK Downloader\n",
      "---------------------------------------------------------------------------\n",
      "    d) Download   l) List    u) Update   c) Config   h) Help   q) Quit\n",
      "---------------------------------------------------------------------------\n",
      "Downloader> l\n",
      "\n",
      "Packages:\n",
      "  [ ] abc................. Australian Broadcasting Commission 2006\n",
      "  [ ] alpino.............. Alpino Dutch Treebank\n",
      "  [ ] averaged_perceptron_tagger Averaged Perceptron Tagger\n",
      "  [ ] averaged_perceptron_tagger_ru Averaged Perceptron Tagger (Russian)\n",
      "  [ ] basque_grammars..... Grammars for Basque\n",
      "  [ ] biocreative_ppi..... BioCreAtIvE (Critical Assessment of Information\n",
      "                           Extraction Systems in Biology)\n",
      "  [ ] bllip_wsj_no_aux.... BLLIP Parser: WSJ Model\n",
      "  [ ] book_grammars....... Grammars from NLTK Book\n",
      "  [*] brown............... Brown Corpus\n",
      "  [ ] brown_tei........... Brown Corpus (TEI XML Version)\n",
      "  [ ] cess_cat............ CESS-CAT Treebank\n",
      "  [ ] cess_esp............ CESS-ESP Treebank\n",
      "  [ ] chat80.............. Chat-80 Data Files\n",
      "  [ ] city_database....... City Database\n",
      "  [ ] cmudict............. The Carnegie Mellon Pronouncing Dictionary (0.6)\n",
      "  [ ] comparative_sentences Comparative Sentence Dataset\n",
      "  [ ] comtrans............ ComTrans Corpus Sample\n",
      "  [ ] conll2000........... CONLL 2000 Chunking Corpus\n",
      "  [ ] conll2002........... CONLL 2002 Named Entity Recognition Corpus\n",
      "Hit Enter to continue: \n",
      "  [ ] conll2007........... Dependency Treebanks from CoNLL 2007 (Catalan\n",
      "                           and Basque Subset)\n",
      "  [ ] crubadan............ Crubadan Corpus\n",
      "  [ ] dependency_treebank. Dependency Parsed Treebank\n",
      "  [ ] dolch............... Dolch Word List\n",
      "  [*] europarl_raw........ Sample European Parliament Proceedings Parallel\n",
      "                           Corpus\n",
      "  [ ] floresta............ Portuguese Treebank\n",
      "  [ ] framenet_v15........ FrameNet 1.5\n",
      "  [ ] framenet_v17........ FrameNet 1.7\n",
      "  [ ] gazetteers.......... Gazeteer Lists\n",
      "  [ ] genesis............. Genesis Corpus\n",
      "  [ ] gutenberg........... Project Gutenberg Selections\n",
      "  [ ] ieer................ NIST IE-ER DATA SAMPLE\n",
      "  [ ] inaugural........... C-Span Inaugural Address Corpus\n",
      "  [ ] indian.............. Indian Language POS-Tagged Corpus\n",
      "  [ ] jeita............... JEITA Public Morphologically Tagged Corpus (in\n",
      "                           ChaSen format)\n",
      "  [ ] kimmo............... PC-KIMMO Data Files\n",
      "  [ ] knbc................ KNB Corpus (Annotated blog corpus)\n",
      "  [ ] large_grammars...... Large context-free and feature-based grammars\n",
      "                           for parser comparison\n",
      "Hit Enter to continue: \n",
      "  [ ] lin_thesaurus....... Lin's Dependency Thesaurus\n",
      "  [ ] mac_morpho.......... MAC-MORPHO: Brazilian Portuguese news text with\n",
      "                           part-of-speech tags\n",
      "  [ ] machado............. Machado de Assis -- Obra Completa\n",
      "  [ ] masc_tagged......... MASC Tagged Corpus\n",
      "  [ ] maxent_ne_chunker... ACE Named Entity Chunker (Maximum entropy)\n",
      "  [ ] maxent_treebank_pos_tagger Treebank Part of Speech Tagger (Maximum entropy)\n",
      "  [ ] moses_sample........ Moses Sample Models\n",
      "  [ ] movie_reviews....... Sentiment Polarity Dataset Version 2.0\n",
      "  [ ] mte_teip5........... MULTEXT-East 1984 annotated corpus 4.0\n",
      "  [ ] mwa_ppdb............ The monolingual word aligner (Sultan et al.\n",
      "                           2015) subset of the Paraphrase Database.\n",
      "  [ ] names............... Names Corpus, Version 1.3 (1994-03-29)\n",
      "  [ ] nombank.1.0......... NomBank Corpus 1.0\n",
      "  [ ] nonbreaking_prefixes Non-Breaking Prefixes (Moses Decoder)\n",
      "  [ ] nps_chat............ NPS Chat\n",
      "  [ ] omw................. Open Multilingual Wordnet\n",
      "  [ ] opinion_lexicon..... Opinion Lexicon\n",
      "  [ ] panlex_swadesh...... PanLex Swadesh Corpora\n",
      "  [ ] paradigms........... Paradigm Corpus\n",
      "  [ ] pe08................ Cross-Framework and Cross-Domain Parser\n",
      "                           Evaluation Shared Task\n",
      "Hit Enter to continue: \n",
      "  [ ] perluniprops........ perluniprops: Index of Unicode Version 7.0.0\n",
      "                           character properties in Perl\n",
      "  [ ] pil................. The Patient Information Leaflet (PIL) Corpus\n",
      "  [ ] pl196x.............. Polish language of the XX century sixties\n",
      "  [ ] porter_test......... Porter Stemmer Test Files\n",
      "  [ ] ppattach............ Prepositional Phrase Attachment Corpus\n",
      "  [ ] problem_reports..... Problem Report Corpus\n",
      "  [ ] product_reviews_1... Product Reviews (5 Products)\n",
      "  [ ] product_reviews_2... Product Reviews (9 Products)\n",
      "  [ ] propbank............ Proposition Bank Corpus 1.0\n",
      "  [ ] pros_cons........... Pros and Cons\n",
      "  [ ] ptb................. Penn Treebank\n",
      "  [*] punkt............... Punkt Tokenizer Models\n",
      "  [ ] qc.................. Experimental Data for Question Classification\n",
      "  [ ] reuters............. The Reuters-21578 benchmark corpus, ApteMod\n",
      "                           version\n",
      "  [ ] rslp................ RSLP Stemmer (Removedor de Sufixos da Lingua\n",
      "                           Portuguesa)\n",
      "  [ ] rte................. PASCAL RTE Challenges 1, 2, and 3\n",
      "  [ ] sample_grammars..... Sample Grammars\n",
      "  [ ] semcor.............. SemCor 3.0\n",
      "Hit Enter to continue: \n",
      "  [ ] senseval............ SENSEVAL 2 Corpus: Sense Tagged Text\n",
      "  [ ] sentence_polarity... Sentence Polarity Dataset v1.0\n",
      "  [ ] sentiwordnet........ SentiWordNet\n",
      "  [ ] shakespeare......... Shakespeare XML Corpus Sample\n",
      "  [ ] sinica_treebank..... Sinica Treebank Corpus Sample\n",
      "  [ ] smultron............ SMULTRON Corpus Sample\n",
      "  [ ] snowball_data....... Snowball Data\n",
      "  [ ] spanish_grammars.... Grammars for Spanish\n",
      "  [ ] state_union......... C-Span State of the Union Address Corpus\n",
      "  [ ] stopwords........... Stopwords Corpus\n",
      "  [ ] subjectivity........ Subjectivity Dataset v1.0\n",
      "  [ ] swadesh............. Swadesh Wordlists\n",
      "  [ ] switchboard......... Switchboard Corpus Sample\n",
      "  [ ] tagsets............. Help on Tagsets\n",
      "  [ ] timit............... TIMIT Corpus Sample\n",
      "  [ ] toolbox............. Toolbox Sample Files\n",
      "  [*] treebank............ Penn Treebank Sample\n",
      "  [ ] twitter_samples..... Twitter Samples\n",
      "  [ ] udhr2............... Universal Declaration of Human Rights Corpus\n",
      "                           (Unicode Version)\n",
      "  [ ] udhr................ Universal Declaration of Human Rights Corpus\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTclError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/nltk/downloader.py\u001b[0m in \u001b[0;36m_interactive_download\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    981\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 982\u001b[0;31m                 \u001b[0mDownloaderGUI\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmainloop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    983\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mTclError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/nltk/downloader.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, dataserver, use_threads)\u001b[0m\n\u001b[1;32m   1225\u001b[0m         \u001b[0;31m# Create the main window.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1226\u001b[0;31m         \u001b[0mtop\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtop\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTk\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1227\u001b[0m         \u001b[0mtop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgeometry\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'+50+50'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/tkinter/__init__.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, screenName, baseName, className, useTk, sync, use)\u001b[0m\n\u001b[1;32m   2016\u001b[0m         \u001b[0minteractive\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2017\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtk\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_tkinter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscreenName\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbaseName\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclassName\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minteractive\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwantobjects\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0museTk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msync\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2018\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0museTk\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTclError\u001b[0m: no display name and no $DISPLAY environment variable",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36m_input_request\u001b[0;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[1;32m    729\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 730\u001b[0;31m                 \u001b[0mident\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreply\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstdin_socket\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    731\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/jupyter_client/session.py\u001b[0m in \u001b[0;36mrecv\u001b[0;34m(self, socket, mode, content, copy)\u001b[0m\n\u001b[1;32m    795\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 796\u001b[0;31m             \u001b[0mmsg_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msocket\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv_multipart\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    797\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mzmq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mZMQError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/zmq/sugar/socket.py\u001b[0m in \u001b[0;36mrecv_multipart\u001b[0;34m(self, flags, copy, track)\u001b[0m\n\u001b[1;32m    394\u001b[0m         \"\"\"\n\u001b[0;32m--> 395\u001b[0;31m         \u001b[0mparts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mflags\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrack\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrack\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    396\u001b[0m         \u001b[0;31m# have first part already, only loop while more to receive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mzmq/backend/cython/socket.pyx\u001b[0m in \u001b[0;36mzmq.backend.cython.socket.Socket.recv (zmq/backend/cython/socket.c:7683)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mzmq/backend/cython/socket.pyx\u001b[0m in \u001b[0;36mzmq.backend.cython.socket.Socket.recv (zmq/backend/cython/socket.c:7460)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mzmq/backend/cython/socket.pyx\u001b[0m in \u001b[0;36mzmq.backend.cython.socket._recv_copy (zmq/backend/cython/socket.c:2344)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/zmq/backend/cython/checkrc.pxd\u001b[0m in \u001b[0;36mzmq.backend.cython.checkrc._check_rc (zmq/backend/cython/socket.c:9621)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: ",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-28-a1a554e5d735>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mnltk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdownload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/nltk/downloader.py\u001b[0m in \u001b[0;36mdownload\u001b[0;34m(self, info_or_id, download_dir, quiet, force, prefix, halt_on_error, raise_on_error)\u001b[0m\n\u001b[1;32m    659\u001b[0m             \u001b[0;31m# function should make a new copy of self to use?\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    660\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mdownload_dir\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_download_dir\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdownload_dir\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 661\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_interactive_download\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    662\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    663\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/nltk/downloader.py\u001b[0m in \u001b[0;36m_interactive_download\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    982\u001b[0m                 \u001b[0mDownloaderGUI\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmainloop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    983\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mTclError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 984\u001b[0;31m                 \u001b[0mDownloaderShell\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    985\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    986\u001b[0m             \u001b[0mDownloaderShell\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/nltk/downloader.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1012\u001b[0m                     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1013\u001b[0m                     self._ds.list(self._ds.download_dir, header=False,\n\u001b[0;32m-> 1014\u001b[0;31m                                   more_prompt=True)\n\u001b[0m\u001b[1;32m   1015\u001b[0m                 \u001b[0;32melif\u001b[0m \u001b[0mcommand\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'h'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1016\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_simple_interactive_help\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/nltk/downloader.py\u001b[0m in \u001b[0;36mlist\u001b[0;34m(self, download_dir, show_packages, show_collections, header, more_prompt, skip_installed)\u001b[0m\n\u001b[1;32m    479\u001b[0m                 \u001b[0mlines\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'\\n'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# for more_prompt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    480\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mmore_prompt\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mlines\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m20\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 481\u001b[0;31m                     \u001b[0muser_input\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Hit Enter to continue: \"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    482\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0muser_input\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m'x'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'q'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    483\u001b[0m                     \u001b[0mlines\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36mraw_input\u001b[0;34m(self, prompt)\u001b[0m\n\u001b[1;32m    703\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_ident\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    704\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_header\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 705\u001b[0;31m             \u001b[0mpassword\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    706\u001b[0m         )\n\u001b[1;32m    707\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36m_input_request\u001b[0;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[1;32m    733\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    734\u001b[0m                 \u001b[0;31m# re-raise KeyboardInterrupt, to truncate traceback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 735\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    736\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    737\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "nltk.download()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extracting Articles from Specific Categories\n",
    "\n",
    "This is my first attempt at processing the Wikipedia dump.  It streamingly parses the Wikipedia XML and processes any article with a category tag that contains the specified strings.  Currently, it just writes the body of the articles to both a single file and a category specific file.  It probably should also do the tokenization, but doesn't yet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class ArticleProcessor:\n",
    "    \n",
    "    def __init__(self, categories):\n",
    "        self.categories = categories        \n",
    "        self.global_matcher = re.compile(\"\\[\\[Category:[^\\]]*(\" + \n",
    "                                         \"|\".join(categories) + \n",
    "                                         \")[^\\]]*\", re.IGNORECASE)\n",
    "        self.category_matcher = {}\n",
    "        self.article_writer = {}\n",
    "        self.global_writer = open(\"data/all-articles\", \"w\")\n",
    "        for category in self.categories:\n",
    "            self.category_matcher[category] = re.compile(\"\\[\\[Category:[^\\]]*\" + \n",
    "                                                         category + \n",
    "                                                         \"[^\\]]*\", re.IGNORECASE)\n",
    "            self.article_writer[category] = open(\"data/\" + category + \"-articles\", \"w\")\n",
    "            \n",
    "    def is_article_of_interest(self, article_text):\n",
    "        return self.global_matcher.search(article_text)\n",
    "\n",
    "    def process_article(self, article_text):\n",
    "        self.global_writer.write(article_text)\n",
    "        self.global_writer.write(\"\\n\")\n",
    "        for category in self.categories:\n",
    "            if self.category_matcher[category].search(article_text):\n",
    "                self.article_writer[category].write(article_text)\n",
    "                self.article_writer[category].write(\"\\n\")\n",
    "    \n",
    "    def close_all(self):\n",
    "        self.global_writer.close()\n",
    "        for writer in self.article_writer.values():\n",
    "            writer.close()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7d400b5563d145e8bc9973d3d331497b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f3c1ec1d3c62421eaf29cf924126f38c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b4c65b3e106148d6a4193acf90e6f695",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Articles: 17773690 Time: 5338.332955360413 seconds\n"
     ]
    }
   ],
   "source": [
    "p = ET.iterparse(\"data/enwiki-20170820-pages-articles.xml\", \n",
    "                 events=(\"start\", \"end\"))\n",
    "\n",
    "start = time.time()\n",
    "article_count = 0\n",
    "root = None\n",
    "f = FloatProgress(min=0, max=17773690)\n",
    "t = IntText(value=0, description=\"Articles\")\n",
    "m = IntText(value=0, description=\"Matching Articles\")\n",
    "display(t, m, f)\n",
    "\n",
    "processor = ArticleProcessor([\"sportspeople\",\n",
    "                              \"artists\",\n",
    "                              \"politicians\",\n",
    "                              \"military personnel\",\n",
    "                              \"scientist\",\n",
    "                              #sportmanager\n",
    "                              #cleric\n",
    "                              \"monarch\",\n",
    "                              \"Fictional\\ characters\",\n",
    "                              \"nobility\",\n",
    "                              \"criminals\",\n",
    "                              \"judges\"\n",
    "                              \n",
    "                             ])\n",
    "try:\n",
    "    \n",
    "    for event, elem in p:\n",
    "        if root == None:\n",
    "            root = elem\n",
    "        if event == \"end\" and elem.tag == '{http://www.mediawiki.org/xml/export-0.10/}text':\n",
    "            article_count += 1\n",
    "            if article_count % 1000 == 0:\n",
    "                f.value = article_count\n",
    "                t.value = article_count\n",
    "            if elem.text and processor.is_article_of_interest(elem.text):\n",
    "                m.value += 1 \n",
    "                processor.process_article(elem.text)\n",
    "            root.clear()\n",
    "finally:\n",
    "    processor.close_all()\n",
    "    print(\"Articles:\", article_count, \"Time:\", (time.time() - start), \"seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Extracting Articles with Gender Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>wiki id</th>\n",
       "      <th>gender</th>\n",
       "      <th>name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>307</td>\n",
       "      <td>MALE</td>\n",
       "      <td>Abraham Lincoln</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>339</td>\n",
       "      <td>FEMALE</td>\n",
       "      <td>Ayn Rand</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>340</td>\n",
       "      <td>MALE</td>\n",
       "      <td>Alain Connes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>344</td>\n",
       "      <td>MALE</td>\n",
       "      <td>Allan Dwan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>595</td>\n",
       "      <td>MALE</td>\n",
       "      <td>Andre Agassi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>628</td>\n",
       "      <td>MALE</td>\n",
       "      <td>Aldous Huxley</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>676</td>\n",
       "      <td>MALE</td>\n",
       "      <td>Andrei Tarkovsky</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>700</td>\n",
       "      <td>MALE</td>\n",
       "      <td>Arthur Schopenhauer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>711</td>\n",
       "      <td>MALE</td>\n",
       "      <td>Albert Sidney Johnston</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>736</td>\n",
       "      <td>MALE</td>\n",
       "      <td>Albert Einstein</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   wiki id  gender                    name\n",
       "0      307    MALE         Abraham Lincoln\n",
       "1      339  FEMALE                Ayn Rand\n",
       "2      340    MALE            Alain Connes\n",
       "3      344    MALE              Allan Dwan\n",
       "4      595    MALE            Andre Agassi\n",
       "5      628    MALE           Aldous Huxley\n",
       "6      676    MALE        Andrei Tarkovsky\n",
       "7      700    MALE     Arthur Schopenhauer\n",
       "8      711    MALE  Albert Sidney Johnston\n",
       "9      736    MALE         Albert Einstein"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gender_label_table = pd.read_csv(\"data/wiki.genders.txt\", sep='\\t')\n",
    "gender_label_table.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "862171"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wiki_ids_with_gender = set([str(x) for x in gender_label_table[\"wiki id\"]])\n",
    "len(gender_label_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1d0b8ff04d3d4361a94da666546c232f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9d8b547b386842569ef87eb3976880b7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "76c57fea5fb84351aae803ad65ec1a1b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "p = ET.iterparse(\"data/enwiki-20170820-pages-articles.xml\", \n",
    "                 events=(\"start\", \"end\"))\n",
    "\n",
    "start = time.time()\n",
    "article_count = 0\n",
    "root = None\n",
    "f = FloatProgress(min=0, max=17773690)\n",
    "t = IntText(value=0, description=\"Articles\")\n",
    "m = IntText(value=0, description=\"Matching Articles\")\n",
    "display(t, m, f)\n",
    "\n",
    "article = None\n",
    "id = None\n",
    "\n",
    "article_writer = open(\"data/gendered-labeled-articles\", \"w\")\n",
    "\n",
    "try:\n",
    "    is_current_article_labeled = False\n",
    "    for event, elem in p:\n",
    "        if root == None:\n",
    "            root = elem\n",
    "        if event == \"start\" and elem.tag == '{http://www.mediawiki.org/xml/export-0.10/}page':\n",
    "            id = None\n",
    "        if id == None and event == \"end\" and elem.tag == '{http://www.mediawiki.org/xml/export-0.10/}id':\n",
    "            is_current_article_labeled = (elem.text in wiki_ids_with_gender)\n",
    "            id = elem.text\n",
    "        if event == \"end\" and elem.tag == '{http://www.mediawiki.org/xml/export-0.10/}text':\n",
    "            article_count += 1\n",
    "            if article_count % 1000 == 0:\n",
    "                f.value = article_count\n",
    "                t.value = article_count\n",
    "            if is_current_article_labeled and elem.text:\n",
    "                m.value += 1 \n",
    "                article = elem.text\n",
    "                article_writer.write(id)\n",
    "                article_writer.write(' ')\n",
    "                article_writer.write(article.replace('\\n', ' '))\n",
    "                article_writer.write('\\n')\n",
    "            root.clear()\n",
    "finally:\n",
    "    article_writer.close()\n",
    "    print(\"Articles:\", article_count, \"Time:\", (time.time() - start), \"seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['{',\n",
       " '{',\n",
       " 'Infobox',\n",
       " 'Martial',\n",
       " 'art',\n",
       " '|',\n",
       " 'logosize',\n",
       " '=',\n",
       " '40px',\n",
       " '|',\n",
       " 'image',\n",
       " '=',\n",
       " 'Shihonage.jpg',\n",
       " '|',\n",
       " 'imagecaption',\n",
       " '=',\n",
       " 'A',\n",
       " 'version',\n",
       " 'of',\n",
       " 'the',\n",
       " '``',\n",
       " 'four-direction',\n",
       " 'throw',\n",
       " \"''\",\n",
       " '(',\n",
       " \"''shihōnage\",\n",
       " \"''\",\n",
       " ')',\n",
       " 'with',\n",
       " 'standing',\n",
       " 'attacker',\n",
       " 'and',\n",
       " 'seated',\n",
       " 'defender',\n",
       " '.',\n",
       " '|',\n",
       " 'imagesize',\n",
       " '=',\n",
       " '300px',\n",
       " '|',\n",
       " 'alt',\n",
       " '=',\n",
       " 'A',\n",
       " 'man',\n",
       " 'kneeling',\n",
       " 'throws',\n",
       " 'another',\n",
       " 'man',\n",
       " 'from',\n",
       " 'a',\n",
       " 'standing',\n",
       " 'position',\n",
       " ';',\n",
       " 'both',\n",
       " 'are',\n",
       " 'wearing',\n",
       " 'robes',\n",
       " '|',\n",
       " 'name',\n",
       " '=',\n",
       " 'Aikido',\n",
       " '<',\n",
       " 'br',\n",
       " '>',\n",
       " '(',\n",
       " '{',\n",
       " '{',\n",
       " 'lang|ja|合気道',\n",
       " '}',\n",
       " '}',\n",
       " ')',\n",
       " '|',\n",
       " 'aka',\n",
       " '=',\n",
       " '|',\n",
       " 'focus',\n",
       " '=',\n",
       " '[',\n",
       " '[',\n",
       " 'Grappling',\n",
       " ']',\n",
       " ']',\n",
       " 'and',\n",
       " '[',\n",
       " '[',\n",
       " 'Soft',\n",
       " 'style|softness',\n",
       " ']',\n",
       " ']',\n",
       " '<',\n",
       " '!',\n",
       " '--',\n",
       " 'see',\n",
       " 'the',\n",
       " 'many',\n",
       " 'discussions',\n",
       " 'at',\n",
       " 'Talk',\n",
       " ':',\n",
       " 'Aikido',\n",
       " '--',\n",
       " '>',\n",
       " '|',\n",
       " 'hardness',\n",
       " '=',\n",
       " '|',\n",
       " 'country',\n",
       " '=',\n",
       " '[',\n",
       " '[',\n",
       " 'Japan',\n",
       " ']',\n",
       " ']',\n",
       " '|',\n",
       " 'creator',\n",
       " '=',\n",
       " '[',\n",
       " '[',\n",
       " 'Morihei',\n",
       " 'Ueshiba',\n",
       " ']',\n",
       " ']',\n",
       " '|',\n",
       " 'famous',\n",
       " 'pract',\n",
       " '=',\n",
       " '[',\n",
       " '[',\n",
       " 'Kisshomaru',\n",
       " 'Ueshiba',\n",
       " ']',\n",
       " ']',\n",
       " ',',\n",
       " '[',\n",
       " '[',\n",
       " 'Moriteru',\n",
       " 'Ueshiba',\n",
       " ']',\n",
       " ']',\n",
       " ',',\n",
       " '[',\n",
       " '[',\n",
       " 'Christian',\n",
       " 'Tissier',\n",
       " ']',\n",
       " ']',\n",
       " ',',\n",
       " '[',\n",
       " '[',\n",
       " 'Morihiro',\n",
       " 'Saito',\n",
       " ']',\n",
       " ']',\n",
       " ',',\n",
       " '[',\n",
       " '[',\n",
       " 'Koichi',\n",
       " 'Tohei',\n",
       " ']',\n",
       " ']',\n",
       " ',',\n",
       " '[',\n",
       " '[',\n",
       " 'Yoshimitsu',\n",
       " 'Yamada',\n",
       " ']',\n",
       " ']',\n",
       " ',',\n",
       " '[',\n",
       " '[',\n",
       " 'Gozo',\n",
       " 'Shioda',\n",
       " ']',\n",
       " ']',\n",
       " ',',\n",
       " '[',\n",
       " '[',\n",
       " 'Mitsugi',\n",
       " 'Saotome',\n",
       " ']',\n",
       " ']',\n",
       " ',',\n",
       " '[',\n",
       " '[',\n",
       " 'Steven',\n",
       " 'Seagal',\n",
       " ']',\n",
       " ']',\n",
       " '|',\n",
       " 'parenthood',\n",
       " '=',\n",
       " '|',\n",
       " 'ancestor',\n",
       " 'arts',\n",
       " '=',\n",
       " '[',\n",
       " '[',\n",
       " 'Daitō-ryū',\n",
       " 'Aiki-jūjutsu',\n",
       " ']',\n",
       " ']',\n",
       " '|',\n",
       " 'descendant',\n",
       " 'arts',\n",
       " '=',\n",
       " '|',\n",
       " 'olympic',\n",
       " '=',\n",
       " '|',\n",
       " 'website',\n",
       " '=',\n",
       " '}',\n",
       " '}',\n",
       " '[',\n",
       " '[',\n",
       " 'File',\n",
       " ':',\n",
       " 'Indonesia',\n",
       " 'and',\n",
       " 'Malaysia',\n",
       " 'Aikido',\n",
       " 'Demonstration',\n",
       " '(',\n",
       " 'Block',\n",
       " '3.3',\n",
       " ')',\n",
       " 'at',\n",
       " 'WCG',\n",
       " '2013.webm|thumb|Aikido',\n",
       " 'Demonstration',\n",
       " ',',\n",
       " '2013',\n",
       " ']',\n",
       " ']',\n",
       " '{',\n",
       " '{',\n",
       " 'Nihongo|',\n",
       " \"''\",\n",
       " \"'Aikido\",\n",
       " \"''\",\n",
       " \"'|合気道|aikidō|lead=yes\",\n",
       " '}',\n",
       " '}',\n",
       " '{',\n",
       " '{',\n",
       " 'IPA-ja|aikiꜜdoː|',\n",
       " '}',\n",
       " '}',\n",
       " 'is',\n",
       " 'a',\n",
       " '[',\n",
       " '[',\n",
       " 'gendai',\n",
       " 'budō|modern',\n",
       " ']',\n",
       " ']',\n",
       " '[',\n",
       " '[',\n",
       " 'Japanese',\n",
       " 'martial',\n",
       " 'art',\n",
       " ']',\n",
       " ']',\n",
       " 'developed',\n",
       " 'by',\n",
       " '[',\n",
       " '[',\n",
       " 'Morihei',\n",
       " 'Ueshiba',\n",
       " ']',\n",
       " ']',\n",
       " 'as',\n",
       " 'a',\n",
       " 'synthesis',\n",
       " 'of',\n",
       " 'his',\n",
       " 'martial',\n",
       " 'studies',\n",
       " ',',\n",
       " 'philosophy',\n",
       " ',',\n",
       " 'and',\n",
       " 'religious',\n",
       " 'beliefs',\n",
       " '.',\n",
       " 'Aikido',\n",
       " 'is',\n",
       " 'often',\n",
       " 'translated',\n",
       " 'as',\n",
       " '``',\n",
       " 'the',\n",
       " 'way',\n",
       " 'of',\n",
       " 'unifying',\n",
       " '(',\n",
       " 'with',\n",
       " ')',\n",
       " '[',\n",
       " '[',\n",
       " 'Qi|life',\n",
       " 'energy',\n",
       " ']',\n",
       " ']',\n",
       " \"''\",\n",
       " '<',\n",
       " 'ref',\n",
       " '>',\n",
       " '{',\n",
       " '{',\n",
       " 'cite',\n",
       " 'book',\n",
       " '|',\n",
       " 'last',\n",
       " '=',\n",
       " 'Saotome',\n",
       " '|',\n",
       " 'first',\n",
       " '=',\n",
       " 'Mitsugi',\n",
       " '|',\n",
       " 'title',\n",
       " '=',\n",
       " 'The',\n",
       " 'Principles',\n",
       " 'of',\n",
       " 'Aikido',\n",
       " '|',\n",
       " 'publisher',\n",
       " '=',\n",
       " 'Shambhala',\n",
       " '|',\n",
       " 'year',\n",
       " '=',\n",
       " '1989',\n",
       " '|',\n",
       " 'page',\n",
       " '=',\n",
       " '222',\n",
       " '|',\n",
       " 'location',\n",
       " '=',\n",
       " 'Boston',\n",
       " ',',\n",
       " 'Massachusetts',\n",
       " '|',\n",
       " 'isbn',\n",
       " '=',\n",
       " '978-0-87773-409-3',\n",
       " '}',\n",
       " '}',\n",
       " '<',\n",
       " '/ref',\n",
       " '>',\n",
       " 'or',\n",
       " 'as',\n",
       " '``',\n",
       " 'the',\n",
       " 'way',\n",
       " 'of',\n",
       " 'harmonious',\n",
       " 'spirit',\n",
       " \"''\",\n",
       " '.',\n",
       " '<',\n",
       " 'ref',\n",
       " 'name=',\n",
       " \"''\",\n",
       " 'ADS',\n",
       " \"''\",\n",
       " '>',\n",
       " '{',\n",
       " '{',\n",
       " 'cite',\n",
       " 'book',\n",
       " '|',\n",
       " 'last',\n",
       " '=',\n",
       " 'Westbrook',\n",
       " '|',\n",
       " 'first',\n",
       " '=',\n",
       " 'Adele',\n",
       " '|last2=Ratti',\n",
       " '|first2=Oscar',\n",
       " '|',\n",
       " 'title',\n",
       " '=',\n",
       " 'Aikido',\n",
       " 'and',\n",
       " 'the',\n",
       " 'Dynamic',\n",
       " 'Sphere',\n",
       " '|',\n",
       " 'publisher',\n",
       " '=',\n",
       " 'Charles',\n",
       " 'E.',\n",
       " 'Tuttle',\n",
       " 'Company',\n",
       " '|',\n",
       " 'year',\n",
       " '=',\n",
       " '1970',\n",
       " '|',\n",
       " 'pages',\n",
       " '=',\n",
       " '16–96',\n",
       " '|',\n",
       " 'location',\n",
       " '=',\n",
       " 'Tokyo',\n",
       " ',',\n",
       " 'Japan',\n",
       " '|',\n",
       " 'isbn',\n",
       " '=',\n",
       " '978-0-8048-0004-4',\n",
       " '}',\n",
       " '}',\n",
       " '<',\n",
       " '/ref',\n",
       " '>',\n",
       " 'Ueshiba',\n",
       " \"'s\",\n",
       " 'goal',\n",
       " 'was',\n",
       " 'to',\n",
       " 'create',\n",
       " 'an',\n",
       " 'art',\n",
       " 'that',\n",
       " 'practitioners',\n",
       " 'could',\n",
       " 'use',\n",
       " 'to',\n",
       " 'defend',\n",
       " 'themselves',\n",
       " 'while',\n",
       " 'also',\n",
       " 'protecting',\n",
       " 'their',\n",
       " 'attacker',\n",
       " 'from',\n",
       " 'injury.',\n",
       " '<',\n",
       " 'ref',\n",
       " '>',\n",
       " '{',\n",
       " '{',\n",
       " 'cite',\n",
       " 'book',\n",
       " '|',\n",
       " 'last',\n",
       " '=',\n",
       " 'Sharif',\n",
       " '|',\n",
       " 'first',\n",
       " '=',\n",
       " 'Suliaman',\n",
       " '|',\n",
       " 'title',\n",
       " '=',\n",
       " '50',\n",
       " 'Martial',\n",
       " 'Arts',\n",
       " 'Myths',\n",
       " '|',\n",
       " 'publisher',\n",
       " '=',\n",
       " 'New',\n",
       " 'Media',\n",
       " 'Entertainment',\n",
       " '|',\n",
       " 'year',\n",
       " '=',\n",
       " '2009',\n",
       " '|',\n",
       " 'page',\n",
       " '=',\n",
       " '135',\n",
       " '|',\n",
       " 'isbn',\n",
       " '=',\n",
       " '978-0-9677546-2-8',\n",
       " '}',\n",
       " '}',\n",
       " '<',\n",
       " '/ref',\n",
       " '>',\n",
       " '<',\n",
       " 'ref',\n",
       " '>',\n",
       " '{',\n",
       " '{',\n",
       " 'cite',\n",
       " 'book',\n",
       " '|',\n",
       " 'last',\n",
       " '=',\n",
       " 'Ueshiba',\n",
       " '|',\n",
       " 'first',\n",
       " '=',\n",
       " 'Kisshōmaru',\n",
       " '|',\n",
       " 'title',\n",
       " '=',\n",
       " 'The',\n",
       " 'Art',\n",
       " 'of',\n",
       " 'Aikido',\n",
       " ':',\n",
       " 'Principles',\n",
       " 'and',\n",
       " 'Essential',\n",
       " 'Techniques',\n",
       " '|',\n",
       " 'publisher',\n",
       " '=',\n",
       " 'Kodansha',\n",
       " 'International',\n",
       " '|',\n",
       " 'year',\n",
       " '=',\n",
       " '2004',\n",
       " '|',\n",
       " 'page',\n",
       " '=',\n",
       " '70',\n",
       " '|',\n",
       " 'isbn',\n",
       " '=',\n",
       " '4-7700-2945-4',\n",
       " '}',\n",
       " '}',\n",
       " '<',\n",
       " '/ref',\n",
       " '>',\n",
       " 'Aikido',\n",
       " \"'s\",\n",
       " 'techniques',\n",
       " 'include',\n",
       " ':',\n",
       " '[',\n",
       " '[',\n",
       " 'irimi',\n",
       " ']',\n",
       " ']',\n",
       " '(',\n",
       " 'entering',\n",
       " ')',\n",
       " ',',\n",
       " 'turning',\n",
       " 'movements',\n",
       " '(',\n",
       " 'that',\n",
       " 'redirect',\n",
       " 'the',\n",
       " 'opponent',\n",
       " \"'s\",\n",
       " 'attack',\n",
       " '[',\n",
       " '[',\n",
       " 'momentum',\n",
       " ']',\n",
       " ']',\n",
       " ')',\n",
       " ',',\n",
       " 'various',\n",
       " 'types',\n",
       " 'of',\n",
       " '[',\n",
       " '[',\n",
       " 'Throw',\n",
       " '(',\n",
       " 'grappling',\n",
       " ')',\n",
       " '|throw',\n",
       " ']',\n",
       " ']',\n",
       " 's',\n",
       " 'and',\n",
       " '[',\n",
       " '[',\n",
       " 'joint',\n",
       " 'lock',\n",
       " ']',\n",
       " ']',\n",
       " 's',\n",
       " ')',\n",
       " '.',\n",
       " '<',\n",
       " 'ref',\n",
       " 'name=',\n",
       " \"''\",\n",
       " 'Aikido',\n",
       " \"''\",\n",
       " '>',\n",
       " '{',\n",
       " '{',\n",
       " 'cite',\n",
       " 'encyclopedia',\n",
       " '|last=Pranin',\n",
       " '|first=Stanley',\n",
       " '|title=Aikido',\n",
       " '|encyclopedia=Encyclopedia',\n",
       " 'of',\n",
       " 'Aikido',\n",
       " '|year=2006',\n",
       " '|url=http',\n",
       " ':',\n",
       " '//www.aikidojournal.com/encyclopedia.php',\n",
       " '?',\n",
       " 'entryID=18',\n",
       " '|deadurl=yes',\n",
       " '|archiveurl=https',\n",
       " ':',\n",
       " '//web.archive.org/web/20061206050153/http',\n",
       " ':',\n",
       " '//www.aikidojournal.com/encyclopedia.php',\n",
       " '?',\n",
       " 'entryID=18',\n",
       " '|archivedate=6',\n",
       " 'December',\n",
       " '2006',\n",
       " '|df=',\n",
       " '}',\n",
       " '}',\n",
       " '<',\n",
       " '/ref',\n",
       " '>',\n",
       " 'Aikido',\n",
       " 'derives',\n",
       " 'mainly',\n",
       " 'from',\n",
       " 'the',\n",
       " 'martial',\n",
       " 'art',\n",
       " 'of',\n",
       " '[',\n",
       " '[',\n",
       " 'Daitō-ryū',\n",
       " 'Aiki-jūjutsu',\n",
       " ']',\n",
       " ']',\n",
       " ',',\n",
       " 'but',\n",
       " 'began',\n",
       " 'to',\n",
       " 'diverge',\n",
       " 'from',\n",
       " 'it',\n",
       " 'in',\n",
       " 'the',\n",
       " 'late',\n",
       " '1920s',\n",
       " ',',\n",
       " 'partly',\n",
       " 'due',\n",
       " 'to',\n",
       " 'Ueshiba',\n",
       " \"'s\",\n",
       " 'involvement',\n",
       " 'with',\n",
       " 'the',\n",
       " '[',\n",
       " '[',\n",
       " 'Oomoto|Ōmoto-kyō',\n",
       " ']',\n",
       " ']',\n",
       " 'religion',\n",
       " '.',\n",
       " 'Ueshiba',\n",
       " \"'s\",\n",
       " 'early',\n",
       " 'students',\n",
       " \"'\",\n",
       " 'documents',\n",
       " 'bear',\n",
       " 'the',\n",
       " 'term',\n",
       " \"''aiki-jūjutsu\",\n",
       " \"''\",\n",
       " '.',\n",
       " '<',\n",
       " 'ref',\n",
       " 'name=',\n",
       " \"''\",\n",
       " 'Pranin-Aikijujutsu',\n",
       " \"''\",\n",
       " '>',\n",
       " '{',\n",
       " '{',\n",
       " 'cite',\n",
       " 'encyclopedia',\n",
       " '|last=Pranin',\n",
       " '|first=Stanley',\n",
       " '|title=Aikijujutsu',\n",
       " '|encyclopedia=Encyclopedia',\n",
       " 'of',\n",
       " 'Aikido',\n",
       " '|year=2006',\n",
       " '|url=http',\n",
       " ':',\n",
       " '//www.aikidojournal.com/encyclopedia',\n",
       " '?',\n",
       " 'entryID=31',\n",
       " '|deadurl=yes',\n",
       " '|archiveurl=https',\n",
       " ':',\n",
       " '//web.archive.org/web/20140826192614/http',\n",
       " ':',\n",
       " '//www.aikidojournal.com/encyclopedia',\n",
       " '?',\n",
       " 'entryID=31',\n",
       " '|archivedate=26',\n",
       " 'August',\n",
       " '2014',\n",
       " '|df=',\n",
       " '}',\n",
       " '}',\n",
       " '<',\n",
       " '/ref',\n",
       " '>',\n",
       " 'Ueshiba',\n",
       " \"'s\",\n",
       " 'senior',\n",
       " 'students',\n",
       " 'have',\n",
       " 'different',\n",
       " 'approaches',\n",
       " 'to',\n",
       " 'aikido',\n",
       " ',',\n",
       " 'depending',\n",
       " 'partly',\n",
       " 'on',\n",
       " 'when',\n",
       " 'they',\n",
       " 'studied',\n",
       " 'with',\n",
       " 'him',\n",
       " '.',\n",
       " 'Today',\n",
       " 'aikido',\n",
       " 'is',\n",
       " 'found',\n",
       " 'all',\n",
       " 'over',\n",
       " 'the',\n",
       " 'world',\n",
       " 'in',\n",
       " 'a',\n",
       " 'number',\n",
       " 'of',\n",
       " 'styles',\n",
       " ',',\n",
       " 'with',\n",
       " 'broad',\n",
       " 'ranges',\n",
       " 'of',\n",
       " 'interpretation',\n",
       " 'and',\n",
       " 'emphasis',\n",
       " '.',\n",
       " 'However',\n",
       " ',',\n",
       " 'they',\n",
       " 'all',\n",
       " 'share',\n",
       " 'techniques',\n",
       " 'formulated',\n",
       " 'by',\n",
       " 'Ueshiba',\n",
       " 'and',\n",
       " 'most',\n",
       " 'have',\n",
       " 'concern',\n",
       " 'for',\n",
       " 'the',\n",
       " 'well-being',\n",
       " 'of',\n",
       " 'the',\n",
       " 'attacker',\n",
       " '.',\n",
       " '==Etymology',\n",
       " 'and',\n",
       " 'basic',\n",
       " 'philosophy==',\n",
       " '[',\n",
       " '[',\n",
       " 'File',\n",
       " ':',\n",
       " '合氣道.svg|thumb|80px|',\n",
       " \"''\",\n",
       " 'Aikidō',\n",
       " \"''\",\n",
       " 'written',\n",
       " 'with',\n",
       " '``',\n",
       " '[',\n",
       " '[',\n",
       " 'Qi|ki',\n",
       " ']',\n",
       " ']',\n",
       " \"''\",\n",
       " 'in',\n",
       " 'its',\n",
       " '[',\n",
       " '[',\n",
       " 'Kyūjitai|old',\n",
       " 'character',\n",
       " 'form',\n",
       " ']',\n",
       " ']',\n",
       " ']',\n",
       " ']',\n",
       " 'The',\n",
       " 'word',\n",
       " '``',\n",
       " 'aikido',\n",
       " \"''\",\n",
       " 'is',\n",
       " 'formed',\n",
       " 'of',\n",
       " 'three',\n",
       " '[',\n",
       " '[',\n",
       " 'kanji',\n",
       " ']',\n",
       " ']',\n",
       " ':',\n",
       " '*',\n",
       " '{',\n",
       " '{',\n",
       " 'lang|ja|',\n",
       " '[',\n",
       " '[',\n",
       " 'wikt',\n",
       " ':',\n",
       " 'en',\n",
       " ':',\n",
       " '合|合',\n",
       " ']',\n",
       " ']',\n",
       " '}',\n",
       " '}',\n",
       " '&',\n",
       " 'nbsp',\n",
       " ';',\n",
       " '–',\n",
       " \"''ai\",\n",
       " \"''\",\n",
       " '&',\n",
       " 'nbsp',\n",
       " ';',\n",
       " '–',\n",
       " 'joining',\n",
       " ',',\n",
       " 'unifying',\n",
       " ',',\n",
       " 'combining',\n",
       " ',',\n",
       " 'fitting',\n",
       " '*',\n",
       " '{',\n",
       " '{',\n",
       " 'lang|ja|',\n",
       " '[',\n",
       " '[',\n",
       " 'wikt',\n",
       " ':',\n",
       " 'en',\n",
       " ':',\n",
       " '気|気',\n",
       " ']',\n",
       " ']',\n",
       " '}',\n",
       " '}',\n",
       " '&',\n",
       " 'nbsp',\n",
       " ';',\n",
       " '–',\n",
       " \"''ki\",\n",
       " \"''\",\n",
       " '&',\n",
       " 'nbsp',\n",
       " ';',\n",
       " '–',\n",
       " 'spirit',\n",
       " ',',\n",
       " 'energy',\n",
       " ',',\n",
       " 'mood',\n",
       " ',',\n",
       " 'morale',\n",
       " '*',\n",
       " '{',\n",
       " '{',\n",
       " 'lang|ja|',\n",
       " '[',\n",
       " '[',\n",
       " 'wikt',\n",
       " ':',\n",
       " 'en',\n",
       " ':',\n",
       " '道|道',\n",
       " ']',\n",
       " ']',\n",
       " '}',\n",
       " '}',\n",
       " '&',\n",
       " 'nbsp',\n",
       " ';',\n",
       " '–',\n",
       " \"''dō\",\n",
       " \"''\",\n",
       " '&',\n",
       " 'nbsp',\n",
       " ';',\n",
       " '–',\n",
       " 'way',\n",
       " ',',\n",
       " 'path',\n",
       " 'The',\n",
       " 'term',\n",
       " \"''\",\n",
       " '[',\n",
       " '[',\n",
       " 'Aiki',\n",
       " '(',\n",
       " 'martial',\n",
       " 'arts',\n",
       " 'principle',\n",
       " ')',\n",
       " '|aiki',\n",
       " ']',\n",
       " ']',\n",
       " \"''\",\n",
       " 'does',\n",
       " 'not',\n",
       " 'readily',\n",
       " 'appear',\n",
       " 'in',\n",
       " 'the',\n",
       " 'Japanese',\n",
       " 'language',\n",
       " 'outside',\n",
       " 'the',\n",
       " 'scope',\n",
       " 'of',\n",
       " '[',\n",
       " '[',\n",
       " 'budō',\n",
       " ']',\n",
       " ']',\n",
       " '.',\n",
       " 'This',\n",
       " 'has',\n",
       " 'led',\n",
       " 'to',\n",
       " 'many',\n",
       " 'possible',\n",
       " 'interpretations',\n",
       " 'of',\n",
       " 'the',\n",
       " 'word',\n",
       " '.',\n",
       " '{',\n",
       " '{',\n",
       " 'lang|ja|合',\n",
       " '}',\n",
       " '}',\n",
       " 'is',\n",
       " 'mainly',\n",
       " 'used',\n",
       " 'in',\n",
       " 'compounds',\n",
       " 'to',\n",
       " 'mean',\n",
       " \"'combine\",\n",
       " ',',\n",
       " 'unite',\n",
       " ',',\n",
       " 'join',\n",
       " 'together',\n",
       " ',',\n",
       " 'meet',\n",
       " \"'\",\n",
       " ',',\n",
       " 'examples',\n",
       " 'being',\n",
       " '{',\n",
       " '{',\n",
       " 'lang|ja|合同',\n",
       " '}',\n",
       " '}',\n",
       " '(',\n",
       " 'combined/united',\n",
       " ...]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_tokenize(article)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
